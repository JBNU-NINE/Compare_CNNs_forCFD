# Comparison of CNN-based deep learning architectures for unsteady CFD acceleration on small datasets

This study compares advanced convolutional neural network (CNN) architectures for accelerating unsteady computational fluid dynamics (CFD) simulations using small datasets based on a challenging natural convection flow dataset. The advanced architectures such as autoencoders, UNet, and ConvLSTM-UNet, were evaluated under identical conditions to determine their predictive accuracy and robustness in autoregressive time-series predictions. ConvLSTM-UNet consistently outperformed other models, particularly in difference value calculation, achieving lower maximum errors and stable residuals. However, error accumulation remains a challenge, limiting reliable predictions to approximately 10 timesteps. This highlights the need for enhanced strategies to improve long-term prediction stability. The novelty of this work lies in its fair comparison of state-of-the-art CNN models within the RePIT framework, demonstrating their potential for accelerating CFD simulations while identifying limitations under small data conditions. Future research will focus on integrating physics-informed loss functions and transfer learning, leveraging additional CFD solver data to refine predictions and mitigate error propagation. Additionally, improvements with exploring alternative models, such as graph neural networks and implicit neural representations, will be investigated. These efforts aim to develop a robust hybrid approach for long-term unsteady CFD acceleration, contributing to practical applications in industries such as nuclear reactor design.